{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "      <td>XR_SHOULDER positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "      <td>XR_SHOULDER positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "      <td>XR_SHOULDER positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
       "      <td>XR_SHOULDER positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
       "      <td>XR_SHOULDER positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path            class_name\n",
       "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study...  XR_SHOULDER positive\n",
       "1  MURA-v1.1/train/XR_SHOULDER/patient00001/study...  XR_SHOULDER positive\n",
       "2  MURA-v1.1/train/XR_SHOULDER/patient00001/study...  XR_SHOULDER positive\n",
       "3  MURA-v1.1/train/XR_SHOULDER/patient00002/study...  XR_SHOULDER positive\n",
       "4  MURA-v1.1/train/XR_SHOULDER/patient00002/study...  XR_SHOULDER positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Load the CSV containing image paths\n",
    "csv_path = \"train_image_paths.csv\"\n",
    "df = pd.read_csv(csv_path, header=None, names=['image_path'])\n",
    "\n",
    "# Extract class from the path\n",
    "def extract_class(path):\n",
    "    parts = path.split('/')\n",
    "    body_part = parts[2]\n",
    "    study_type = parts[4]\n",
    "    label = study_type.split('_')[1]\n",
    "    return f\"{body_part} {label}\"\n",
    "\n",
    "df['class_name'] = df['image_path'].apply(extract_class)\n",
    "\n",
    "# Show the DataFrame\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Labeled Image Paths\", dataframe=df)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_image_labeled.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the DataFrame with class names to a new CSV file\n",
    "new_csv_path = \"train_image_labeled.csv\"\n",
    "df.to_csv(new_csv_path, index=False)\n",
    "\n",
    "new_csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with class names to a new CSV file\n",
    "df.to_csv(new_csv_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_path', 'class_name'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = r\"train_image_labeled.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Select random samples from the dataframe\n",
    "sampled_df = df.sample(n=6).reset_index(drop=True)\n",
    "\n",
    "# Plot random images with class names\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, row in sampled_df.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    class_label = row['class_name']\n",
    "    \n",
    "    # Check if file exists before loading\n",
    "    if os.path.exists(image_path):\n",
    "        image = Image.open(image_path).convert('L')  # Convert to grayscale for X-rays\n",
    "        axes[idx].imshow(image, cmap='gray')\n",
    "        axes[idx].set_title(class_label)\n",
    "        axes[idx].axis('off')\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, 'Image Not Found', ha='center', va='center')\n",
    "        axes[idx].set_title(\"Missing Image\")\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "      <td>XR_SHOULDER positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "      <td>XR_SHOULDER positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00001/study...</td>\n",
       "      <td>XR_SHOULDER positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
       "      <td>XR_SHOULDER positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURA-v1.1/train/XR_SHOULDER/patient00002/study...</td>\n",
       "      <td>XR_SHOULDER positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36803</th>\n",
       "      <td>MURA-v1.1/train/XR_HAND/patient11183/study1_ne...</td>\n",
       "      <td>XR_HAND negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36804</th>\n",
       "      <td>MURA-v1.1/train/XR_HAND/patient11183/study1_ne...</td>\n",
       "      <td>XR_HAND negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36805</th>\n",
       "      <td>MURA-v1.1/train/XR_HAND/patient11184/study1_ne...</td>\n",
       "      <td>XR_HAND negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36806</th>\n",
       "      <td>MURA-v1.1/train/XR_HAND/patient11184/study1_ne...</td>\n",
       "      <td>XR_HAND negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36807</th>\n",
       "      <td>MURA-v1.1/train/XR_HAND/patient11184/study1_ne...</td>\n",
       "      <td>XR_HAND negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36808 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_path            class_name\n",
       "0      MURA-v1.1/train/XR_SHOULDER/patient00001/study...  XR_SHOULDER positive\n",
       "1      MURA-v1.1/train/XR_SHOULDER/patient00001/study...  XR_SHOULDER positive\n",
       "2      MURA-v1.1/train/XR_SHOULDER/patient00001/study...  XR_SHOULDER positive\n",
       "3      MURA-v1.1/train/XR_SHOULDER/patient00002/study...  XR_SHOULDER positive\n",
       "4      MURA-v1.1/train/XR_SHOULDER/patient00002/study...  XR_SHOULDER positive\n",
       "...                                                  ...                   ...\n",
       "36803  MURA-v1.1/train/XR_HAND/patient11183/study1_ne...      XR_HAND negative\n",
       "36804  MURA-v1.1/train/XR_HAND/patient11183/study1_ne...      XR_HAND negative\n",
       "36805  MURA-v1.1/train/XR_HAND/patient11184/study1_ne...      XR_HAND negative\n",
       "36806  MURA-v1.1/train/XR_HAND/patient11184/study1_ne...      XR_HAND negative\n",
       "36807  MURA-v1.1/train/XR_HAND/patient11184/study1_ne...      XR_HAND negative\n",
       "\n",
       "[36808 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = \"D:\\\\Downloads\\\\MURA-v1.1\\\\MURA-v1.1\"  # Adjust if nested\n",
    "df = pd.read_csv(os.path.join(BASE_DIR, \"train_image_labeled.csv\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\085\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\085\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from training set...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Base directory for the dataset\n",
    "BASE_DIR = \"D:\\\\Downloads\\\\MURA-v1.1\\\\MURA-v1.1\"  # Adjust if nested\n",
    "df = pd.read_csv(os.path.join(BASE_DIR, \"train_image_labeled.csv\"))\n",
    "\n",
    "# Select 500 images per class\n",
    "df = df.groupby('class_name').sample(n=500, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Preprocessing for MobileNet (ImageNet normalization)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = preprocess(image)\n",
    "    return image\n",
    "\n",
    "# Custom Dataset Class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, base_dir=BASE_DIR):\n",
    "        self.df = df\n",
    "        self.base_dir = base_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        relative_path = self.df.iloc[idx, 0]\n",
    "        image_path = os.path.join(self.base_dir, relative_path.lstrip(\"MURA-v1.1/\"))\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "        image = preprocess_image(image_path)\n",
    "        label = self.df.iloc[idx, 1]\n",
    "        return image, label\n",
    "\n",
    "# Label Encoding\n",
    "label_map = {label: idx for idx, label in enumerate(np.unique(df['class_name']))}\n",
    "df['class_name'] = df['class_name'].map(label_map)\n",
    "\n",
    "# Reverse label map for prediction output\n",
    "reverse_label_map = {idx: label for label, idx in label_map.items()}\n",
    "\n",
    "# Split the data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = ImageDataset(train_df, base_dir=BASE_DIR)\n",
    "val_dataset = ImageDataset(val_df, base_dir=BASE_DIR)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load pre-trained MobileNetV2 and remove the classifier\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "mobilenet = nn.Sequential(*list(mobilenet.children())[:-1])  # Remove the last layer\n",
    "mobilenet.eval()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mobilenet.to(device)\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, lbls in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.view(outputs.size(0), -1)  # Flatten\n",
    "            features.append(outputs.cpu().numpy())\n",
    "            labels.append(lbls.numpy())\n",
    "    return np.vstack(features), np.concatenate(labels)\n",
    "\n",
    "# Extract features\n",
    "print(\"Extracting features from training set...\")\n",
    "train_features, train_labels = extract_features(train_loader, mobilenet)\n",
    "print(\"Extracting features from validation set...\")\n",
    "val_features, val_labels = extract_features(val_loader, mobilenet)\n",
    "\n",
    "# Train SVM classifier\n",
    "print(\"Training SVM classifier...\")\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(train_features, train_labels)\n",
    "\n",
    "# Save the SVM model\n",
    "model_save_path = os.path.join(BASE_DIR, \"svm_model.joblib\")\n",
    "joblib.dump(svm, model_save_path)\n",
    "print(f\"SVM model saved to {model_save_path}\")\n",
    "\n",
    "# Load the SVM model (for demonstration; in practice, you’d load it in a separate script)\n",
    "loaded_svm = joblib.load(model_save_path)\n",
    "print(\"SVM model loaded successfully\")\n",
    "\n",
    "# Validate the loaded model\n",
    "val_predictions = loaded_svm.predict(val_features)\n",
    "print(classification_report(val_labels, val_predictions, target_names=[label for label, idx in label_map.items()]))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(val_labels, val_predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[label for label in label_map], yticklabels=[label for label in label_map])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SVM model (for demonstration; in practice, you’d load it in a separate script)\n",
    "loaded_svm = joblib.load(model_save_path)\n",
    "print(\"SVM model loaded successfully\")\n",
    "#Validate the loaded model\n",
    "val_predictions = loaded_svm.predict(val_features)\n",
    "print(classification_report(val_labels, val_predictions, target_names=[label for label, idx in label_map.items()]))\n",
    "\n",
    "# Single image prediction function\n",
    "def predict_single_image(image_path, mobilenet_model, svm_model, reverse_label_map):\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image_path)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Extract features with MobileNet\n",
    "    mobilenet_model.to(device)\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        features = mobilenet_model(image)\n",
    "        features = features.view(features.size(0), -1).cpu().numpy()\n",
    "    \n",
    "    # Predict with SVM\n",
    "    prediction = svm_model.predict(features)\n",
    "    predicted_label = reverse_label_map[prediction[0]]\n",
    "    return predicted_label\n",
    "\n",
    "# Example usage of single image prediction\n",
    "example_image_path = \"D:\\\\Downloads\\\\MURA-v1.1\\\\MURA-v1.1\\\\train\\\\XR_FOREARM\\\\patient09309\\\\study1_negative\\\\image2.png\"  # Replace with a valid path\n",
    "try:\n",
    "    predicted_class = predict_single_image(example_image_path, mobilenet, loaded_svm, reverse_label_map)\n",
    "    print(f\"Predicted class for {example_image_path}: {predicted_class}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
